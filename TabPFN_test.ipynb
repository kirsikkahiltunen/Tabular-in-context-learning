{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb82d33-6804-4b72-b072-1618022dbe11",
   "metadata": {},
   "source": [
    "# TabPFN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af109da2-7df9-41f8-8d5f-26ab262cdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, RocCurveDisplay\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "274aeca9-4424-471e-b908-20bfd7c796fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "from tabpfn.constants import ModelVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb4fe32-45d7-4f90-93bd-46acb8984414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26301, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kaisaniemi = pd.read_csv(\"data/Kaisaniemi_2023-2025.csv\")\n",
    "#kumpula = pd.read_csv(\"data/Kumpula_2025.csv\")\n",
    "malmi  = pd.read_csv(\"data/Malmi_2023-2025.csv\")\n",
    "#df = kaisaniemi\n",
    "#df = kumpula\n",
    "df = malmi\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d300ffa4-878b-4596-a085-b4db3ac9efba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2629, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df[df[\"Vallitseva sää\"].isin(['Ei merkittäviä sääilmiöitä ', 'Heikkoa lumisadetta', 'Heikkoja vesikuuroja', 'Utua', 'Heikkoa vesisadetta'])]\n",
    "df = df[df[\"Vallitseva sää\"].isin(['Heikkoa lumisadetta', 'Heikkoja vesikuuroja', 'Utua'])]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a60b941-d55d-4a1d-810a-7988bc5b02d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Running on CPU with more than 1000 samples is not allowed by default due to slow performance.\nTo override this behavior, set the environment variable TABPFN_ALLOW_CPU_LARGE_DATASET=1 or set ignore_pretraining_limits=True.\nAlternatively, consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m25\u001b[39m)\n\u001b[32m      6\u001b[39m classifier = TabPFNClassifier.create_default_for_version(ModelVersion.V2)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m classifier_tabpfn = \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/appl/easybuild/opt/Python/3.12.3-GCCcore-13.3.0/lib/python3.12/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/turso/home/hiltunek/venv/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:320\u001b[39m, in \u001b[36mtrack_model_call.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_safe_call_with_telemetry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_names\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/turso/home/hiltunek/venv/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:364\u001b[39m, in \u001b[36m_safe_call_with_telemetry\u001b[39m\u001b[34m(func, args, kwargs, model_method, param_names)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# Step 2: Run the actual function\u001b[39;00m\n\u001b[32m    363\u001b[39m start = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m duration_ms = \u001b[38;5;28mint\u001b[39m((time.perf_counter() - start) * \u001b[32m1000\u001b[39m)\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m# Step 3: Send telemetry event\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/turso/home/hiltunek/venv/lib/python3.12/site-packages/tabpfn/classifier.py:816\u001b[39m, in \u001b[36mTabPFNClassifier.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    815\u001b[39m     byte_size, rng = \u001b[38;5;28mself\u001b[39m._initialize_model_variables()\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m     ensemble_configs, X, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_dataset_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    817\u001b[39m     \u001b[38;5;28mself\u001b[39m.ensemble_configs_ = ensemble_configs  \u001b[38;5;66;03m# Store for prompt tuning reuse\u001b[39;00m\n\u001b[32m    819\u001b[39m \u001b[38;5;28mself\u001b[39m._maybe_calibrate_temperature_and_tune_decision_thresholds(\n\u001b[32m    820\u001b[39m     X=X,\n\u001b[32m    821\u001b[39m     y=y,\n\u001b[32m    822\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/turso/home/hiltunek/venv/lib/python3.12/site-packages/tabpfn/classifier.py:686\u001b[39m, in \u001b[36mTabPFNClassifier._initialize_dataset_preprocessing\u001b[39m\u001b[34m(self, X, y, rng)\u001b[39m\n\u001b[32m    683\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, torch.Tensor)\n\u001b[32m    684\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._initialize_for_differentiable_input(X=X, y=y, rng=rng)\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_for_standard_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/turso/home/hiltunek/venv/lib/python3.12/site-packages/tabpfn/classifier.py:611\u001b[39m, in \u001b[36mTabPFNClassifier._initialize_for_standard_input\u001b[39m\u001b[34m(self, X, y, rng)\u001b[39m\n\u001b[32m    607\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Initialize the model for standard input.\"\"\"\u001b[39;00m\n\u001b[32m    608\u001b[39m \u001b[38;5;66;03m# TODO: Fix the types later.\u001b[39;00m\n\u001b[32m    609\u001b[39m \u001b[38;5;66;03m# In the following code, we have multiple conversions between DataFrames and\u001b[39;00m\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# NumPy arrays. In a follow-up PR, we will fix this.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m X, y, feature_names, n_features = \u001b[43mensure_compatible_fit_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_num_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference_config_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMAX_NUMBER_OF_SAMPLES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_num_features\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference_config_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMAX_NUMBER_OF_FEATURES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_pretraining_limits\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_pretraining_limits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_y_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevices_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[38;5;66;03m# Set class variables for sklearn compatibility\u001b[39;00m\n\u001b[32m    622\u001b[39m \u001b[38;5;28mself\u001b[39m.feature_names_in_ = feature_names\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/turso/home/hiltunek/venv/lib/python3.12/site-packages/tabpfn/validation.py:56\u001b[39m, in \u001b[36mensure_compatible_fit_inputs\u001b[39m\u001b[34m(X, y, estimator, max_num_samples, max_num_features, ignore_pretraining_limits, ensure_y_numeric, devices)\u001b[39m\n\u001b[32m     43\u001b[39m X, y, feature_names_in, n_features_in = ensure_compatible_fit_inputs_sklearn(\n\u001b[32m     44\u001b[39m     X,\n\u001b[32m     45\u001b[39m     y,\n\u001b[32m     46\u001b[39m     estimator=estimator,\n\u001b[32m     47\u001b[39m     ensure_y_numeric=ensure_y_numeric,\n\u001b[32m     48\u001b[39m )\n\u001b[32m     49\u001b[39m _validate_dataset_size(\n\u001b[32m     50\u001b[39m     num_features=X.shape[\u001b[32m1\u001b[39m],\n\u001b[32m     51\u001b[39m     num_samples=X.shape[\u001b[32m0\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m     ignore_pretraining_limits=ignore_pretraining_limits,\n\u001b[32m     55\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43m_validate_num_samples_for_cpu\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_cpu_override\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_pretraining_limits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, feature_names_in, n_features_in\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/turso/home/hiltunek/venv/lib/python3.12/site-packages/tabpfn/validation.py:252\u001b[39m, in \u001b[36m_validate_num_samples_for_cpu\u001b[39m\u001b[34m(devices, num_samples, allow_cpu_override)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(device.type == \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m devices):\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m num_samples > \u001b[32m1000\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    253\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mRunning on CPU with more than 1000 samples is not allowed \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    254\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mby default due to slow performance.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTo override this behavior, set the environment variable \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    256\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTABPFN_ALLOW_CPU_LARGE_DATASET=1 or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mset ignore_pretraining_limits=True.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAlternatively, consider using a GPU or the tabpfn-client API: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    259\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhttps://github.com/PriorLabs/tabpfn-client\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m         )\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m num_samples > \u001b[32m200\u001b[39m:\n\u001b[32m    262\u001b[39m         warnings.warn(\n\u001b[32m    263\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mRunning on CPU with more than 200 samples may be slow.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    264\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mConsider using a GPU or the tabpfn-client API: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    265\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhttps://github.com/PriorLabs/tabpfn-client\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    266\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    267\u001b[39m         )\n",
      "\u001b[31mRuntimeError\u001b[39m: Running on CPU with more than 1000 samples is not allowed by default due to slow performance.\nTo override this behavior, set the environment variable TABPFN_ALLOW_CPU_LARGE_DATASET=1 or set ignore_pretraining_limits=True.\nAlternatively, consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"Vallitseva sää\", axis=1)\n",
    "y = df[\"Vallitseva sää\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "\n",
    "classifier = TabPFNClassifier.create_default_for_version(ModelVersion.V2)\n",
    "classifier_tabpfn = classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb40fc1-9540-4d4a-82f6-b31cd4699e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = classifier_tabpfn.predict(X_test)\n",
    "y_score = classifier_tabpfn.predict_proba(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_predict)\n",
    "precision = precision_score(y_test, y_predict, average=None)\n",
    "recall = recall_score(y_test, y_predict, average=None)\n",
    "f1 = f1_score(y_test, y_predict, average=None)\n",
    "print(f\"accuracy: {acc}\")\n",
    "print(f\"precision score: {precision}\")\n",
    "print(f\"recall score: {recall}\")\n",
    "print(f\"f1-score: {f1}\")\n",
    "\n",
    "y_predict = pd.Series(y_predict)\n",
    "results = pd.concat([y_test.reset_index(drop=True), y_predict.reset_index(drop=True)], axis=1)\n",
    "results.columns = [\"correct_label\", \"prediction\"]\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c580a3c-8650-44b8-a50b-1680a579110b",
   "metadata": {},
   "source": [
    "## One-vs-Rest multiclass ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f23af96-cd0d-4c79-bddc-4ece60c66bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "onehot_y_test = label_binarizer.transform(y_test)\n",
    "class_of_interest = 'Heikkoa lumisadetta'\n",
    "class_indices = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "\n",
    "display = RocCurveDisplay.from_predictions(\n",
    "    onehot_y_test[:, class_indices],\n",
    "    y_score[:, class_indices],\n",
    "    name=f\"{class_of_interest} vs the rest\",\n",
    "    curve_kwargs=dict(color=\"blue\"),\n",
    "    plot_chance_level=True,\n",
    "    despine=True,\n",
    ")\n",
    "_ = display.ax_.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"One-vs-Rest ROC curves: \\nHeikkoa lumisadetta vs (Heikkoja vesikuuroja & Utua)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d7cb3-d921-4c00-bec3-0c5910833056",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "onehot_y_test = label_binarizer.transform(y_test)\n",
    "class_of_interest = 'Heikkoja vesikuuroja'\n",
    "class_indices = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "\n",
    "display = RocCurveDisplay.from_predictions(\n",
    "    onehot_y_test[:, class_indices],\n",
    "    y_score[:, class_indices],\n",
    "    name=f\"{class_of_interest} vs the rest\",\n",
    "    curve_kwargs=dict(color=\"darkorange\"),\n",
    "    plot_chance_level=True,\n",
    "    despine=True,\n",
    ")\n",
    "_ = display.ax_.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"One-vs-Rest ROC curves: \\nHeikkoja vesikuuroja vs (Heikkoa lumisadetta & Utua)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5fe7d-8010-459e-8550-12186e03ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "onehot_y_test = label_binarizer.transform(y_test)\n",
    "class_of_interest = 'Utua'\n",
    "class_indices = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "\n",
    "display = RocCurveDisplay.from_predictions(\n",
    "    onehot_y_test[:, class_indices],\n",
    "    y_score[:, class_indices],\n",
    "    name=f\"{class_of_interest} vs the rest\",\n",
    "    curve_kwargs=dict(color=\"green\"),\n",
    "    plot_chance_level=True,\n",
    "    despine=True,\n",
    ")\n",
    "_ = display.ax_.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"One-vs-Rest ROC curves: \\nUtua vs (Heikkoa lumisadetta & Heikkoja vesikuuroja)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde80a22-0822-4030-b13d-7aed64775c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "colors = [\"blue\", \"darkorange\", \"green\"]\n",
    "classes = [\"Heikkoa lumisadetta\", \"Heikkoja vesikuuroja\", \"Utua\"]\n",
    "for class_of_interest, color in zip(classes, colors):\n",
    "    class_indices = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        onehot_y_test[:, class_indices],\n",
    "        y_score[:, class_indices],\n",
    "        name=f\"{class_of_interest} vs the rest\",\n",
    "        curve_kwargs=dict(color=color),\n",
    "        ax=ax,\n",
    "        plot_chance_level=(class_indices==2),\n",
    "        despine=True,\n",
    "    )\n",
    "_=ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"One-vs-Rest ROC curves:\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
